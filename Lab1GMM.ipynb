{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Žygimantas Augustas Nemura 2110605 VGG19 [Strawberry, Bee, Goldfish]"
      ],
      "metadata": {
        "id": "HahtG4wGG6e5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut8SGWcnxm_u"
      },
      "source": [
        "Gauname nuotraukų"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9MRum63xgRF",
        "outputId": "23580ee5-e499-483d-9939-3352a4c7e39a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openimages\n",
            "  Using cached openimages-0.0.1-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting boto3 (from openimages)\n",
            "  Using cached boto3-1.37.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting cvdata (from openimages)\n",
            "  Using cached cvdata-0.0.3-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from openimages) (5.3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from openimages) (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from openimages) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openimages) (4.67.1)\n",
            "Collecting botocore<1.38.0,>=1.37.0 (from boto3->openimages)\n",
            "  Downloading botocore-1.37.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->openimages)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3->openimages)\n",
            "  Downloading s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from cvdata->openimages) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from cvdata->openimages) (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from cvdata->openimages) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->openimages) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->openimages) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->openimages) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->openimages) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->openimages) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->openimages) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->openimages) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->openimages) (1.17.0)\n",
            "Downloading openimages-0.0.1-py2.py3-none-any.whl (10 kB)\n",
            "Downloading boto3-1.37.0-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cvdata-0.0.3-py3-none-any.whl (37 kB)\n",
            "Downloading botocore-1.37.0-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3, cvdata, openimages\n",
            "Successfully installed boto3-1.37.0 botocore-1.37.0 cvdata-0.0.3 jmespath-1.0.1 openimages-0.0.1 s3transfer-0.11.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openimages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Zzh469yXy0w0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openimages.download import download_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "q8pdi2Yby2pn"
      },
      "outputs": [],
      "source": [
        "data_dir = \"OpenImages\" # Nurodome direktorija\n",
        "number_for_samples = 333\n",
        "classes = [\"Strawberry\", \"Bee\", \"Goldfish\"] # Pasirinktos klases is OpenImages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QNghiy5LzX0C"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhmUpffgzuEI",
        "outputId": "0a469658-0c03-4f2d-dfee-e05f7e284546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading is starting...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 333/333 [00:06<00:00, 51.26it/s]\n",
            "100%|██████████| 333/333 [00:05<00:00, 56.94it/s]\n",
            "100%|██████████| 333/333 [00:06<00:00, 52.67it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'strawberry': {'images_dir': 'OpenImages/strawberry/images'},\n",
              " 'bee': {'images_dir': 'OpenImages/bee/images'},\n",
              " 'goldfish': {'images_dir': 'OpenImages/goldfish/images'}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "print(\"Downloading is starting...\")\n",
        "download_dataset(data_dir, classes, limit=number_for_samples) #Atsisiunciame nuotraukas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtviX4rU62Iw"
      },
      "source": [
        "Paruošiam transformacijos parametrus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TsqamwR_684z"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "]) # Transformacijos bus reikalingos, kad nuotraukos tiktu modeliui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zam-Iy86j_0"
      },
      "source": [
        "Custom Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y3HpAFbaAQwR"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class GMMDataset(Dataset): # Custom Dataset naudojant pytorch dataset kaip pagrinda\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Priskiriam klasems skaitines reiksmes, kad juos galetu nuskaityti modelis\n",
        "        self.class_to_idx = {\"strawberry\": 0, \"bee\": 1, \"goldfish\": 2}\n",
        "\n",
        "        # Scan the dataset structure correctly\n",
        "        for class_name, class_idx in self.class_to_idx.items():\n",
        "            class_path = os.path.join(data_dir, class_name, \"images\")  # Pasiziurim i klases image aplanka\n",
        "            if os.path.exists(class_path):\n",
        "                for img_name in os.listdir(class_path): # Priskiriam kiekvienai klases nuotraukai po index\n",
        "                    img_path = os.path.join(class_path, img_name)\n",
        "                    self.image_paths.append(img_path)\n",
        "                    self.labels.append(class_idx)\n",
        "\n",
        "        print(f\"Loaded {len(self.image_paths)} images from {data_dir}\")\n",
        "\n",
        "    def __len__(self): # grazinam nuotrauku skaiciu\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\") # Pasiverciam i rgb formata\n",
        "\n",
        "        if self.transform: # Pritaikom transformacijas\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOHoUpg51ck7"
      },
      "source": [
        "Create a dataset and put it in a dataloader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zByi37zxClR5",
        "outputId": "70f113d3-91c0-43e9-f95b-4c6f7d960093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 999 images from OpenImages\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "dataset = GMMDataset(data_dir=\"OpenImages\", transform=transform)\n",
        "\n",
        "# Sukuriam dataloader ir uzkraunam ji su musu dataset\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers = 2)\n",
        "iterator = iter(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr1RTVIHFoT8"
      },
      "source": [
        "Paruošiam pre-trained modelį darbui"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8L5h4-UFt2U",
        "outputId": "195e8c35-85d8-4c38-d401-e1bef067f580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:04<00:00, 126MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): ReLU(inplace=True)\n",
              "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (33): ReLU(inplace=True)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): ReLU(inplace=True)\n",
              "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.vgg19(pretrained=True) # Naudojam modeli vgg19\n",
        "model.eval().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUCF51ghXs5z"
      },
      "source": [
        "Skaičiavimai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIhMmmaCX2Pv",
        "outputId": "22c22c40-2a1f-40ce-e854-c24b6308f132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Strawberry Metrics:\n",
            "  Accuracy : 0.40\n",
            "  Recall   : 1.00\n",
            "  Precision: 0.36\n",
            "  F1-score : 0.52\n",
            "\n",
            "Class Bee Metrics:\n",
            "  Accuracy : 0.44\n",
            "  Recall   : 1.00\n",
            "  Precision: 0.37\n",
            "  F1-score : 0.54\n",
            "\n",
            "Class Goldfish Metrics:\n",
            "  Accuracy : 0.41\n",
            "  Recall   : 0.98\n",
            "  Precision: 0.36\n",
            "  F1-score : 0.53\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Imagenet ID klasiu, kurioms modelis yra treniruotas\n",
        "STRAWBERRY_IDX = 949  # Strawberry\n",
        "BEE_IDX = 309  # Bee\n",
        "GOLDFISH_IDX = 1  # Goldfish\n",
        "\n",
        "ground_truth = []  # Laikom nuotraukos label\n",
        "# Laikome tikimybes, kad nuotraukos atitinka kazkuria klase\n",
        "predictions_strawberry = []\n",
        "predictions_bee = []\n",
        "predictions_goldfish = []\n",
        "\n",
        "# Paduoda visas nuotraukas modeliui ir gauna tikimybes\n",
        "while True:\n",
        "    try:\n",
        "        features, labels = next(iterator)\n",
        "        output = model(features.to(device))\n",
        "\n",
        "        for i in range(output.shape[0]):\n",
        "            predictions = torch.sigmoid(output[i])  # 🔹 Use Sigmoid instead of Softmax\n",
        "\n",
        "            # Extract sigmoid probability for each class\n",
        "            predictions_strawberry = np.append(predictions_strawberry, predictions[STRAWBERRY_IDX].cpu().detach())\n",
        "            predictions_bee = np.append(predictions_bee, predictions[BEE_IDX].cpu().detach())\n",
        "            predictions_goldfish = np.append(predictions_goldfish, predictions[GOLDFISH_IDX].cpu().detach())\n",
        "\n",
        "        ground_truth = np.append(ground_truth, labels)\n",
        "    except StopIteration:\n",
        "        break\n",
        "\n",
        "# Confusion matrica, pritaikom threshold\n",
        "def calculate_confusion_matrix(ground_truth, predictions, class_idx, threshold=0.5):\n",
        "    predictions = np.array(predictions)\n",
        "    predictions_thresholded = (predictions >= threshold).astype(np.float64)\n",
        "\n",
        "    matrix = {\n",
        "        'TP': np.sum((ground_truth == class_idx) & (predictions_thresholded == 1)),\n",
        "        'TN': np.sum((ground_truth != class_idx) & (predictions_thresholded == 0)),\n",
        "        'FP': np.sum((ground_truth != class_idx) & (predictions_thresholded == 1)),\n",
        "        'FN': np.sum((ground_truth == class_idx) & (predictions_thresholded == 0)),\n",
        "    }\n",
        "    return matrix\n",
        "\n",
        "\n",
        "# matavimai\n",
        "def calculate_metrics(TP, TN, FP, FN):\n",
        "    metrics = {}\n",
        "    metrics['accuracy'] = (TP + TN) / (TP + FP + TN + FN)\n",
        "    metrics['recall'] = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    metrics['precision'] = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    metrics['f1'] = 2 * (metrics['recall'] * metrics['precision']) / (metrics['recall'] + metrics['precision']) if (metrics['recall'] + metrics['precision']) else 0\n",
        "    return metrics\n",
        "\n",
        "# Ivertinam kiekviena klase su threshold T=0.5\n",
        "threshold = 0.5\n",
        "matrix_strawberry = calculate_confusion_matrix(ground_truth, predictions_strawberry, 0, threshold)\n",
        "matrix_bee = calculate_confusion_matrix(ground_truth, predictions_bee, 1, threshold)\n",
        "matrix_goldfish = calculate_confusion_matrix(ground_truth, predictions_goldfish, 2, threshold)\n",
        "\n",
        "metrics_strawberry = calculate_metrics(matrix_strawberry['TP'], matrix_strawberry['TN'], matrix_strawberry['FP'], matrix_strawberry['FN'])\n",
        "metrics_bee = calculate_metrics(matrix_bee['TP'], matrix_bee['TN'], matrix_bee['FP'], matrix_bee['FN'])\n",
        "metrics_goldfish = calculate_metrics(matrix_goldfish['TP'], matrix_goldfish['TN'], matrix_goldfish['FP'], matrix_goldfish['FN'])\n",
        "\n",
        "# Rezultatai\n",
        "def print_metrics(metrics, class_name):\n",
        "    print(f'Class {class_name} Metrics:')\n",
        "    print(f'  Accuracy : {metrics[\"accuracy\"]:.2f}')\n",
        "    print(f'  Recall   : {metrics[\"recall\"]:.2f}')\n",
        "    print(f'  Precision: {metrics[\"precision\"]:.2f}')\n",
        "    print(f'  F1-score : {metrics[\"f1\"]:.2f}\\n')\n",
        "\n",
        "\n",
        "print_metrics(metrics_strawberry, \"Strawberry\")\n",
        "print_metrics(metrics_bee, \"Bee\")\n",
        "print_metrics(metrics_goldfish, \"Goldfish\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Individuali nuotrauka"
      ],
      "metadata": {
        "id": "McuTvnxud-ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import urllib\n",
        "\n",
        "# Imagenet klases\n",
        "url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
        "imagenet_classes = urllib.request.urlopen(url).read().decode(\"utf-8\").split(\"\\n\")\n",
        "\n",
        "\n",
        "# Nuotrauka, kuri bus analizuojama\n",
        "image_path = \"dog.jpg\"\n",
        "img = transform(Image.open(image_path)).unsqueeze(0).to(device)  # Pritaikom transformacija\n",
        "\n",
        "# Bandom klasifikuoti\n",
        "with torch.no_grad():\n",
        "    output = model(img)\n",
        "    probabilities = torch.sigmoid(output).squeeze()\n",
        "    predicted_idx = probabilities.argmax().item()\n",
        "\n",
        "# Rezutlatas\n",
        "predicted_class = imagenet_classes[predicted_idx]\n",
        "print(f\"Predicted class: {predicted_class}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC27BGUXeBLj",
        "outputId": "ee692ab6-9b54-4bc8-91be-d3fdeec0cf28"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: Border collie\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}